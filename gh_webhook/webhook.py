"""
Webhookäº‹ä»¶è°ƒåº¦
"""

import asyncio
import json
import time
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Dict, Optional

from loguru import logger

try:
    from .ai_handler import get_unified_ai_handler
except ImportError:
    try:
        from ai_handler import get_unified_ai_handler
    except ImportError:
        get_unified_ai_handler = None
        logger.warning("ç»Ÿä¸€AIå¤„ç†å™¨æ¨¡å—å¯¼å…¥å¤±è´¥, ç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨")

try:
    from .mcp import MCPTools
except ImportError:
    try:
        from mcp import MCPTools
    except ImportError:
        MCPTools = None
        logger.warning("MCPå·¥å…·æ¨¡å—å¯¼å…¥å¤±è´¥, ç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨")


class WebhookEventType(Enum):
    """Webhookäº‹ä»¶ç±»å‹"""

    PUSH = "push"
    PULL_REQUEST = "pull_request"
    ISSUES = "issues"
    ISSUE_COMMENT = "issue_comment"
    PULL_REQUEST_REVIEW = "pull_request_review"
    PULL_REQUEST_REVIEW_COMMENT = "pull_request_review_comment"
    RELEASE = "release"
    STAR = "star"
    FORK = "fork"
    WATCH = "watch"
    CREATE = "create"
    DELETE = "delete"
    WORKFLOW_RUN = "workflow_run"
    WORKFLOW_JOB = "workflow_job"
    REPOSITORY = "repository"
    PING = "ping"


@dataclass
class WebhookEvent:
    """Webhookäº‹ä»¶æ•°æ®ç±»"""

    event_type: str
    delivery_id: str
    signature: str
    payload: Dict[str, Any]
    headers: Dict[str, str]
    timestamp: str
    repository: Optional[str] = None
    processed: bool = False
    error: Optional[str] = None
    raw_body: Optional[bytes] = None  # åŸå§‹è¯·æ±‚ä½“å­—èŠ‚æ•°æ®, ç”¨äºç­¾åéªŒè¯


class WebhookProcessor:
    """Webhookå¤„ç†å™¨"""

    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.utils = None  # å°†åœ¨åˆå§‹åŒ–æ—¶è®¾ç½®
        self.msg_processor = None  # æ¶ˆæ¯å¤„ç†å™¨
        self.github_processor = None  # GitHubå¤„ç†å™¨
        self.unified_ai_handler = None  # ç»Ÿä¸€AIå¤„ç†å™¨
        self.event_stats = defaultdict(int)
        self.last_reset_time = time.time()
        self.delivery_cache = {}  # delivery_id -> timestamp
        self.cache_ttl = 3600  # 1å°æ—¶
        self.event_queue = asyncio.Queue(maxsize=1000)
        self.processing_task = None
        self.is_processing = False
        self.active_reviews = set()  # æ­£åœ¨è¿›è¡Œçš„å®¡æŸ¥: {"repo/name#pr_number"}
        self.review_cache_max_size = 100
        # æ”¯æŒçš„ç±»å‹
        self.supported_events = {
            WebhookEventType.PUSH.value,
            WebhookEventType.PULL_REQUEST.value,
            WebhookEventType.ISSUES.value,
            WebhookEventType.ISSUE_COMMENT.value,
            WebhookEventType.PULL_REQUEST_REVIEW.value,
            WebhookEventType.PULL_REQUEST_REVIEW_COMMENT.value,
            WebhookEventType.RELEASE.value,
            WebhookEventType.STAR.value,
            WebhookEventType.FORK.value,
            WebhookEventType.WATCH.value,
            WebhookEventType.CREATE.value,
            WebhookEventType.DELETE.value,
            WebhookEventType.WORKFLOW_RUN.value,
            WebhookEventType.WORKFLOW_JOB.value,
            WebhookEventType.REPOSITORY.value,
            WebhookEventType.PING.value,
        }

    def set_dependencies(self, utils_module, msg_processor, github_processor, unified_ai_handler):
        """è®¾ç½®ä¾èµ–æ¨¡å—"""
        self.utils = utils_module
        self.msg_processor = msg_processor
        self.github_processor = github_processor
        self.unified_ai_handler = unified_ai_handler

        if self.unified_ai_handler:
            mcp_tools = None
            if MCPTools:
                try:
                    # éœ€è¦å¯¼å…¥ContextManageræ¥åˆ›å»ºMCPå·¥å…·å®ä¾‹
                    from .ai_models import ContextManager
                    from pathlib import Path

                    context_manager = ContextManager(Path("ai_contexts"))
                    mcp_tools = MCPTools(self.config_manager, context_manager, "webhook")
                    logger.success("MCPå·¥å…·å®ä¾‹åˆ›å»ºæˆåŠŸ")
                except Exception as e:
                    logger.error(f"MCPå·¥å…·å®ä¾‹åˆ›å»ºå¤±è´¥: {e}")

            self.unified_ai_handler.set_dependencies(github_processor, mcp_tools=mcp_tools)
            asyncio.create_task(self._initialize_unified_ai())

        logger.success("äº‹ä»¶å¤„ç†å™¨ä¾èµ–æ¨¡å—å·²è®¾ç½®")

    async def _initialize_unified_ai(self):
        """åˆå§‹åŒ–ç»Ÿä¸€AIå¤„ç†å™¨"""
        try:
            if hasattr(self, "unified_ai_handler") and self.unified_ai_handler:
                # å…ˆåˆå§‹åŒ–MCPå·¥å…·
                if self.unified_ai_handler.mcp_tools:
                    logger.info("å¼€å§‹åˆå§‹åŒ–MCPå·¥å…·...")
                    mcp_success = await self.unified_ai_handler.mcp_tools.initialize()
                    if mcp_success:
                        logger.success("MCPå·¥å…·åˆå§‹åŒ–æˆåŠŸ âœ¨")
                    else:
                        logger.error("MCPå·¥å…·åˆå§‹åŒ–å¤±è´¥ âŒ")
                else:
                    logger.warning("MCPå·¥å…·ä¸å¯ç”¨")

                # å†åˆå§‹åŒ–AIå¤„ç†å™¨
                logger.info("å¼€å§‹åˆå§‹åŒ–AIå¤„ç†å™¨...")
                success = await self.unified_ai_handler.initialize()
                if success:
                    logger.success("AIå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ â™ª(Â´â–½ï½€)")
                else:
                    logger.error("AIå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥")
            else:
                logger.warning("AIå¤„ç†å™¨ä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"AIå¤„ç†å™¨åˆå§‹åŒ–å¼‚å¸¸: {e}")

    async def start_processing(self):
        """å¼€å§‹å¤„ç†äº‹ä»¶é˜Ÿåˆ—"""
        if self.is_processing:
            logger.warning("äº‹ä»¶å¤„ç†å·²åœ¨è¿è¡Œä¸­")
            return

        self.is_processing = True
        self.processing_task = asyncio.create_task(self._process_event_queue())

    async def stop_processing(self):
        """åœæ­¢å¤„ç†äº‹ä»¶é˜Ÿåˆ—"""
        if not self.is_processing:
            return

        self.is_processing = False

        if self.processing_task:
            self.processing_task.cancel()
            try:
                await self.processing_task
            except asyncio.CancelledError:
                pass

        logger.info("äº‹ä»¶å¤„ç†å™¨å·²åœæ­¢")

    async def process_webhook(self, webhook_data: Dict[str, Any]) -> bool:
        """å¤„ç†webhookè¯·æ±‚"""
        try:
            event = WebhookEvent(
                event_type=webhook_data.get("event_type", ""),
                delivery_id=webhook_data.get("delivery_id", ""),
                signature=webhook_data.get("signature", ""),
                payload=webhook_data.get("payload", {}),
                headers=webhook_data.get("headers", {}),
                timestamp=webhook_data.get("timestamp", datetime.now().isoformat()),
                raw_body=webhook_data.get("raw_body"),  # ä¼ é€’åŸå§‹å­—èŠ‚æ•°æ®
            )

            # åŸºç¡€éªŒè¯
            if not self._validate_event(event):
                return False
            event.repository = self._extract_repository_name(event.payload)
            if self._is_duplicate_delivery(event.delivery_id):
                logger.info(f"è·³è¿‡é‡å¤æŠ•é€’: {event.delivery_id}")
                return True
            if not event.repository:
                logger.warning(f"æ— æ³•æå–ä»“åº“åç§°: {event.delivery_id}")
                return False
            repo_config = self.config_manager.get_repository_config(event.repository)
            if not repo_config:
                logger.info(f"ä»“åº“ {event.repository} æœªåœ¨é…ç½®æ–‡ä»¶ä¸­, è·³è¿‡å¤„ç†")
                return True
            if not self._is_repository_enabled(event.repository):
                logger.info(f"ä»“åº“æœªå¯ç”¨webhook: {event.repository}")
                return True

            signature_valid = await self._verify_webhook_signature(event)
            # logger.info(f"ç­¾åéªŒè¯ç»“æœ: {signature_valid} for {event.delivery_id}")
            if not signature_valid:
                logger.warning(f"Webhookç­¾åéªŒè¯å¤±è´¥: {event.delivery_id}")
                return False
            try:
                await self.event_queue.put(event)
                logger.info(f"äº‹ä»¶å·²åŠ å…¥å¤„ç†é˜Ÿåˆ—: {event.event_type} - {event.repository} - {event.delivery_id}")
                return True
            except asyncio.QueueFull:
                logger.error(f"äº‹ä»¶é˜Ÿåˆ—å·²æ»¡, ä¸¢å¼ƒäº‹ä»¶: {event.delivery_id}")
                return False

        except Exception as e:
            logger.error(f"å¤„ç†webhookå¼‚å¸¸: {e}")
            return False

    def _validate_event(self, event: WebhookEvent) -> bool:
        """éªŒè¯äº‹ä»¶åŸºç¡€ä¿¡æ¯"""
        if not event.event_type:
            logger.warning("ç¼ºå°‘äº‹ä»¶ç±»å‹")
            return False

        if not event.delivery_id:
            logger.warning("ç¼ºå°‘æŠ•é€’ID")
            return False

        if not event.payload:
            logger.warning("ç¼ºå°‘payloadæ•°æ®")
            return False

        if event.event_type not in self.supported_events:
            logger.info(f"ä¸æ”¯æŒçš„äº‹ä»¶ç±»å‹: {event.event_type}")
            return False

        return True

    def _extract_repository_name(self, payload: Dict[str, Any]) -> Optional[str]:
        """æå–ä»“åº“åç§°"""
        # logger.debug(f"å¼€å§‹æå–ä»“åº“åç§°, payloadç±»å‹: {type(payload)}")
        if not payload:
            logger.warning("payloadä¸ºç©º")
            return None

        if "payload" in payload:
            inner_payload = payload.get("payload", {})
            # logger.debug(f"webhook_dataç»“æ„, å†…éƒ¨payloadç±»å‹: {type(inner_payload)}")
            if inner_payload and isinstance(inner_payload, dict):
                repository = inner_payload.get("repository")
                # logger.debug(f"ä»å†…éƒ¨payloadæå–åˆ°çš„repositoryå­—æ®µ: {repository}")
                if repository and isinstance(repository, dict):
                    full_name = repository.get("full_name")
                    # logger.debug(f"æå–åˆ°çš„full_name: {full_name}")
                    return full_name
        else:
            repository = payload.get("repository")
            # logger.info(f"ä»ç›´æ¥payloadæå–åˆ°çš„repositoryå­—æ®µ: {repository}")
            if repository and isinstance(repository, dict):
                full_name = repository.get("full_name")
                # logger.debug(f"æå–åˆ°çš„full_name: {full_name}")
                return full_name
        logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„repositoryä¿¡æ¯")
        return None

    def _is_duplicate_delivery(self, delivery_id: str) -> bool:
        """æ£€æŸ¥é‡å¤æŠ•é€’"""
        current_time = time.time()
        expired_keys = [
            key for key, timestamp in self.delivery_cache.items() if current_time - timestamp > self.cache_ttl
        ]
        for key in expired_keys:
            del self.delivery_cache[key]
        if delivery_id in self.delivery_cache:
            return True

        self.delivery_cache[delivery_id] = current_time
        return False

    async def _verify_webhook_signature(self, event: WebhookEvent) -> bool:
        """éªŒè¯webhookç­¾å"""
        if not event.repository:
            return False
        repo_config = self.config_manager.get_repository_config(event.repository)
        # logger.info(f"ä»“åº“ {event.repository} é…ç½®æŸ¥è¯¢ç»“æœ: {repo_config}")
        webhook_config = repo_config.get("webhook", {})
        verify_signature = webhook_config.get("verify_signature", repo_config.get("verify_signature", True))
        logger.info(f"ä»“åº“ {event.repository} ç­¾åéªŒè¯è®¾ç½®: {verify_signature}")
        if not verify_signature:
            logger.info(f"ä»“åº“ {event.repository} å·²ç¦ç”¨ç­¾åéªŒè¯")
            return True
        if not self.utils:
            logger.warning("utilsæœªåˆå§‹åŒ–")
            return True
        secret = repo_config.get("webhook_secret")
        if not secret:
            logger.warning(f"ä»“åº“ {event.repository} æœªé…ç½®webhookå¯†é’¥")
            return False

        if event.raw_body is None:
            logger.warning("æœªæ‰¾åˆ°åŸå§‹bodyæ•°æ®, é‡æ–°åºåˆ—åŒ–æ•°æ®éªŒè¯..")
            payload_bytes = json.dumps(event.payload, separators=(",", ":")).encode("utf-8")
        else:
            payload_bytes = event.raw_body

        return self.utils["verify_github_signature"](payload_bytes, event.signature, secret)

    def _is_repository_enabled(self, repository: Optional[str]) -> bool:
        """æ£€æŸ¥ä»“åº“æ˜¯å¦å¯ç”¨"""
        if not repository:
            return False
        repo_config = self.config_manager.get_repository_config(repository)
        if not repo_config:
            return False
        repo_enabled = repo_config.get("enabled", True)
        webhook_config = repo_config.get("webhook", {})
        webhook_enabled = webhook_config.get("enabled", True)
        return repo_enabled and webhook_enabled

    async def _process_event_queue(self):
        """å¤„ç†äº‹ä»¶é˜Ÿåˆ—"""
        consecutive_errors = 0
        max_consecutive_errors = 5
        
        while self.is_processing:
            try:
                event = await asyncio.wait_for(self.event_queue.get(), timeout=1.0)
                await self._handle_single_event(event)
                self.event_queue.task_done()
                consecutive_errors = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                
            except asyncio.TimeoutError:
                # è¶…æ—¶æ˜¯æ­£å¸¸çš„
                continue
            except asyncio.CancelledError:
                logger.info("å¤„ç†ä»»åŠ¡è¢«å–æ¶ˆ")
                break
            except Exception as e:
                consecutive_errors += 1
                logger.error(f"å¤„ç†äº‹ä»¶é˜Ÿåˆ—å¼‚å¸¸ [è¿ç»­é”™è¯¯: {consecutive_errors}/{max_consecutive_errors}]: {e}")
                if consecutive_errors >= max_consecutive_errors:
                    logger.warning(f"è¿ç»­é”™è¯¯è¿‡å¤šï¼Œæš‚åœå¤„ç† 30 ç§’")
                    await asyncio.sleep(30)
                    consecutive_errors = 0
                else:
                    await asyncio.sleep(min(consecutive_errors * 2, 10))  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š10ç§’

    async def _handle_single_event(self, event: WebhookEvent):
        """å¤„ç†å•ä¸ªäº‹ä»¶"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†äº‹ä»¶: {event.event_type} - {event.repository} - {event.delivery_id}")
            self.event_stats[event.event_type] += 1
            # æ ¹æ®äº‹ä»¶ç±»å‹åˆ†å‘å¤„ç†
            success = await self._dispatch_event(event)
            if success:
                event.processed = True
                logger.info(f"äº‹ä»¶å¤„ç†æˆåŠŸ: {event.delivery_id}")
            else:
                event.error = "å¤„ç†å¤±è´¥"
                logger.warning(f"äº‹ä»¶å¤„ç†å¤±è´¥: {event.delivery_id}")

        except Exception as e:
            event.error = str(e)
            logger.error(f"å¤„ç†äº‹ä»¶å¼‚å¸¸: {event.delivery_id} - {e}")

    async def _dispatch_event(self, event: WebhookEvent) -> bool:
        """åˆ†å‘äº‹ä»¶åˆ°ç›¸åº”çš„å¤„ç†å™¨"""
        try:
            # å¹¶è¡Œå¤„ç†ä¸åŒçš„ä»»åŠ¡
            tasks = []
            # æ¶ˆæ¯é€šçŸ¥
            if self.msg_processor:
                tasks.append(self._handle_message_notification(event))
            # GH-APIå¤„ç†
            if self.github_processor and event.event_type in ["issues", "pull_request"]:
                tasks.append(self._handle_github_processing(event))
            # PRå®¡æ ¸
            if event.event_type == "pull_request" and event.payload.get("action") in [
                "review_requested",
                "review_request_removed",
            ]:
                tasks.append(self._handle_review_request(event))
            # ç»Ÿä¸€AIå¤„ç†
            if hasattr(self, "unified_ai_handler") and self.unified_ai_handler:
                if hasattr(self.unified_ai_handler, "mcp_tools") and self.unified_ai_handler.mcp_tools:
                    if hasattr(self.unified_ai_handler, "_is_mcp_tools_initialized"):
                        mcp_ready = self.unified_ai_handler._is_mcp_tools_initialized()
                    else:
                        mcp_ready = (
                            hasattr(self.unified_ai_handler.mcp_tools, "_initialized")
                            and self.unified_ai_handler.mcp_tools._initialized
                        )
                    if mcp_ready:
                        if event.event_type == "issue_comment":
                            tasks.append(self.unified_ai_handler.handle_issue_comment(event.payload))
                        elif event.event_type == "pull_request_review_comment":
                            tasks.append(self.unified_ai_handler.handle_pr_review_comment(event.payload))
                    else:
                        logger.warning(f"MCPå·¥å…·æœªå°±ç»ª, è·³è¿‡AIå¤„ç†: {event.event_type} - {event.repository}")
                else:
                    logger.warning(f"MCPå·¥å…·ä¸å¯ç”¨, è·³è¿‡AIå¤„ç†: {event.event_type} - {event.repository}")
            # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                success_count = 0
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        logger.error(f"ä»»åŠ¡ {i} æ‰§è¡Œå¼‚å¸¸: {result}")
                    elif result:
                        success_count += 1
                return success_count > 0
            return True

        except Exception as e:
            logger.error(f"åˆ†å‘äº‹ä»¶å¼‚å¸¸: {e}")
            return False

    async def _handle_message_notification(self, event: WebhookEvent) -> bool:
        """å¤„ç†æ¶ˆæ¯é€šçŸ¥"""
        try:
            if not self.msg_processor:
                return False
            if not self.config_manager.is_message_type_allowed(event.repository, event.event_type):
                logger.info(f"ä»“åº“ {event.repository} ä¸å…è®¸å‘é€ {event.event_type} ç±»å‹çš„æ¶ˆæ¯, è·³è¿‡å¤„ç†")
                return True  # ä¸æ˜¯é”™è¯¯, åªæ˜¯è·³è¿‡å¤„ç†

            from .msg_req import MessageType

            try:
                event_type_mapping = {
                    "workflow_run": "workflow_run",
                    "pull_request": "pull_request",
                    "issue_comment": "issues",
                    "pull_request_review": "pull_request",
                    "pull_request_review_comment": "pull_request",
                }
                mapped_event_type = event_type_mapping.get(event.event_type, event.event_type)
                message_type = MessageType(mapped_event_type)
            except ValueError:
                logger.warning(f"ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹: {event.event_type}")
                return True  # ä¸æ˜¯é”™è¯¯, åªæ˜¯ä¸å¤„ç†(lazy(

            # event.payloadåŒ…å«åµŒå¥—çš„payloadç»“æ„
            actual_payload = event.payload.get("payload", event.payload)
            message_request = self.msg_processor.create_message_request(message_type, actual_payload, event.repository)
            if message_request:
                return await self.msg_processor.process_message_request(message_request)

            return True

        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯é€šçŸ¥å¼‚å¸¸: {e}")
            return False

    async def _handle_github_processing(self, event: WebhookEvent) -> bool:
        """å¤„ç†GitHubæ“ä½œ"""
        try:
            if not self.github_processor:
                return False
            actual_payload = event.payload.get("payload", event.payload)
            if event.event_type == "issues":
                return await self.github_processor.process_issue_event(actual_payload)
            elif event.event_type == "pull_request":
                return await self.github_processor.process_pr_event(actual_payload)
            return True

        except Exception as e:
            logger.error(f"å¤„ç†GitHubæ“ä½œå¼‚å¸¸: {e}")
            return False

    async def _handle_review_request(self, event: WebhookEvent) -> bool:
        """å¤„ç†PRå®¡æ ¸è¯·æ±‚äº‹ä»¶"""
        try:
            if not self.github_processor:
                return False
            repo_config = self.config_manager.get_repository_config(event.repository)
            if not repo_config:
                return True
            allow_review_config = repo_config.get("allow_review", {})
            if not isinstance(allow_review_config, dict) or not allow_review_config.get("enabled", False):
                return True
            bot_username = allow_review_config.get("bot_username", "")
            if not bot_username:
                logger.warning(f"ä»“åº“ {event.repository} æœªé…ç½®ç”¨æˆ·å")
                return True
            # PRä¿¡æ¯
            pr = event.payload.get("pull_request", {})
            pr_number = pr.get("number")
            action = event.payload.get("action")
            if not pr_number:
                return False
            owner, repo = event.repository.split("/")
            review_requests = await self.github_processor._get_api_client(event.repository).get_pr_review_requests(
                owner, repo, pr_number
            )
            requested_reviewers = [user["login"] for user in review_requests.get("users", [])]

            bot_requested = bot_username in requested_reviewers
            if action == "review_requested" and bot_requested:
                review_key = f"{event.repository}#{pr_number}"
                if review_key in self.active_reviews:
                    logger.info(f"PR {review_key} å·²åœ¨å®¡æŸ¥ä¸­, è·³è¿‡é‡å¤è¯·æ±‚")
                    return True

                if self.unified_ai_handler and hasattr(self.unified_ai_handler, "review_code_changes"):
                    mcp_ready = False
                    if hasattr(self.unified_ai_handler, "mcp_tools") and self.unified_ai_handler.mcp_tools:
                        if hasattr(self.unified_ai_handler, "_is_mcp_tools_initialized"):
                            mcp_ready = self.unified_ai_handler._is_mcp_tools_initialized()
                        else:
                            mcp_ready = (
                                hasattr(
                                    self.unified_ai_handler.mcp_tools,
                                    "_initialized",
                                )
                                and self.unified_ai_handler.mcp_tools._initialized
                            )

                    if mcp_ready:
                        self.active_reviews.add(review_key)
                        if len(self.active_reviews) > self.review_cache_max_size:
                            # ç§»é™¤æœ€æ—§çš„ä¸€äº›æ¡ç›®(ç®€å•å®ç°)
                            excess = len(self.active_reviews) - self.review_cache_max_size
                            for _ in range(excess):
                                self.active_reviews.pop()

                        asyncio.create_task(self._perform_ai_review(event.repository, pr_number, pr))
                        logger.info(f"ğŸ¤– {bot_username} è¢«è¯·æ±‚å®¡æ ¸ PR {event.repository}#{pr_number}, å¯åŠ¨å®¡æŸ¥")
                    else:
                        logger.warning(f"MCPå·¥å…·æœªå°±ç»ª, æ— æ³•å¯åŠ¨AIå®¡æ ¸: {event.repository}#{pr_number}")
                        await self._remove_review_and_comment(
                            owner,
                            repo,
                            pr_number,
                            bot_username,
                            "ğŸš« AIå®¡æŸ¥å·¥å…·æš‚æ—¶ä¸å¯ç”¨, è¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜",
                        )
                else:
                    await self._remove_review_and_comment(
                        owner,
                        repo,
                        pr_number,
                        bot_username,
                        "ğŸš« æœ¬ä»“åº“æœªå…è®¸AIå®¡æŸ¥åŠŸèƒ½",
                    )
            elif action == "review_requested" and not bot_requested:
                pass
            elif action == "review_request_removed" and bot_username in event.payload.get("requested_reviewer", {}).get(
                "login", ""
            ):
                logger.info(f"{bot_username} çš„å®¡æ ¸è¯·æ±‚å·²è¢«ç§»é™¤: {event.repository}#{pr_number}")
            return True

        except Exception as e:
            logger.error(f"å¤„ç†å®¡æ ¸è¯·æ±‚å¼‚å¸¸: {e}")
            return False

    async def _remove_review_and_comment(
        self,
        owner: str,
        repo: str,
        pr_number: int,
        bot_username: str,
        comment_text: str,
    ):
        """ç§»é™¤å®¡æ ¸è¯·æ±‚å¹¶æ·»åŠ è¯„è®º"""
        try:
            api_client = self.github_processor._get_api_client(f"{owner}/{repo}")
            if not api_client:
                return
            await self._check_and_hide_outdated_reviews(api_client, owner, repo, pr_number, bot_username)
            keywords = ["Github Bot", "baiyao105"]
            existing_comment = await api_client.find_bot_comment_by_keywords(
                owner, repo, pr_number, keywords, bot_username
            )
            if existing_comment:
                comment_id = existing_comment.get("id")
                if comment_id:
                    await api_client.update_issue_comment(owner, repo, comment_id, comment_text)
                    logger.success(f"å·²æ›´æ–° PR {owner}/{repo}#{pr_number} çš„è¯„è®º: {comment_text}")
                else:
                    await api_client.create_issue_comment(owner, repo, pr_number, comment_text)
                    logger.success(f"å·²è¯„è®º PR {owner}/{repo}#{pr_number}: {comment_text}")
            else:
                await api_client.create_issue_comment(owner, repo, pr_number, comment_text)
                logger.success(f"å·²è¯„è®º PR {owner}/{repo}#{pr_number}: {comment_text}")
            await api_client.remove_review_request(owner, repo, pr_number, [bot_username])
            logger.success(f"å·²ç§»é™¤ {bot_username} çš„å®¡æ ¸è¯·æ±‚: {owner}/{repo}#{pr_number}")
        except Exception as e:
            logger.error(f"ç§»é™¤å®¡æ ¸è¯·æ±‚å’Œè¯„è®ºå¼‚å¸¸: {e}")

    async def _check_and_hide_outdated_reviews(
        self, api_client, owner: str, repo: str, pr_number: int, bot_username: str
    ):
        """æ£€æŸ¥å¹¶éšè—è¿‡æ—¶çš„å®¡æŸ¥ç»“æœ"""
        try:
            reviews = await api_client.get_pr_reviews(owner, repo, pr_number)
            for review in reviews:
                review_author = review.get("user", {}).get("login", "")
                review_state = review.get("state", "")
                review_id = review.get("id")
                if review_author == bot_username and review_state in ["CHANGES_REQUESTED", "COMMENTED"] and review_id:
                    await api_client.hide_review_as_outdated(owner, repo, review_id)
                    logger.debug(f"éšè—äº†è¿‡æ—¶çš„å®¡æŸ¥ç»“æœ: {owner}/{repo}#{pr_number} review#{review_id}")
        except Exception as e:
            logger.error(f"æ£€æŸ¥å’Œéšè—è¿‡æ—¶å®¡æŸ¥å¼‚å¸¸: {e}")

    async def _perform_ai_review(self, repository: str, pr_number: int, pr_data: Dict[str, Any]):
        """æ‰§è¡Œæ™ºèƒ½ä»£ç å®¡æŸ¥"""
        review_key = f"{repository}#{pr_number}"
        try:
            logger.info(f"ğŸ” å¼€å§‹æ™ºèƒ½ä»£ç å®¡æŸ¥: {repository}#{pr_number}")
            owner, repo = repository.split("/")
            api_client = self.github_processor._get_api_client(repository)
            if not api_client:
                logger.error(f"âŒ æ— æ³•è·å–GitHub APIå®¢æˆ·ç«¯: {repository}")
                return

            # è·å–PRè¯¦ç»†ä¿¡æ¯
            pr_files = await api_client.get_pr_files(owner, repo, pr_number)
            if not pr_files:
                logger.warning(f"âš ï¸ æœªè·å–åˆ°PRæ–‡ä»¶å˜æ›´: {repository}#{pr_number}")
                repo_config = self.config_manager.get_repository_config(repository)
                bot_username = repo_config.get("allow_review", {}).get("bot_username", "")
                await self._remove_review_and_comment(owner, repo, pr_number, bot_username, "ğŸ“ æ— æ³•è·å–PRæ–‡ä»¶å˜æ›´ä¿¡æ¯")
                return
            pr_context = {
                "pull_request": pr_data,
                "files": pr_files,
                "repository": {"full_name": repository},
            }

            review_result = await self.unified_ai_handler.review_code_changes(
                pull_request=pr_data, repository={"full_name": repository}
            )

            if review_result:
                summary = review_result.get("summary", "") if isinstance(review_result, dict) else getattr(review_result, "summary", "")
                if "å®¡æŸ¥å¼‚å¸¸" in str(summary) or "error" in str(summary).lower():
                    logger.error(f"å®¡æŸ¥å¤„ç†å¼‚å¸¸: {repository}#{pr_number}")
                    repo_config = self.config_manager.get_repository_config(repository)
                    bot_username = repo_config.get("allow_review", {}).get("bot_username", "")
                    await self._remove_review_and_comment(
                        owner,
                        repo,
                        pr_number,
                        bot_username,
                        f"""å®¡æŸ¥é‡åˆ°äº†ä¸€äº›é—®é¢˜å‘¢

> [!CAUTION]
> ğŸ”§ **é”™è¯¯ä¿¡æ¯**: {summary}


---
âœ¨ Powered by **baiyao105**' GitHub Bot""",
                    )
                    await api_client.remove_review_request(owner, repo, pr_number, [bot_username])
                    return

                # æäº¤å®¡æ ¸ç»“æœ
                success = await self.github_processor.submit_ai_review(repository, pr_number, review_result)
                if success:
                    logger.info(f"å®¡æŸ¥å®Œæˆå¹¶æäº¤: {repository}#{pr_number}")
                    if self.msg_processor:
                        try:
                            from .msg_req import MessageType
                            if isinstance(review_result, dict):
                                review_data = {
                                    "overall_score": review_result.get("overall_score", 85),
                                    "approved": review_result.get("approved", True),
                                    "summary": review_result.get("summary", review_result.get("review_content", "AIå®¡æŸ¥å®Œæˆ")),
                                    "issues_count": review_result.get("issues_count", {})
                                }
                            else:
                                review_data = {
                                    "overall_score": getattr(review_result, "overall_score", 85),
                                    "approved": getattr(review_result, "approved", True),
                                    "summary": getattr(review_result, "summary", getattr(review_result, "review_content", "AIå®¡æŸ¥å®Œæˆ")),
                                    "issues_count": getattr(review_result, "issues_count", {})
                                }
                            ai_review_payload = {
                                "repository": {"full_name": repository},
                                "pull_request": pr_data,
                                "review_result": review_data
                            }
                            message_request = self.msg_processor.create_message_request(
                                MessageType.AI_REVIEW, ai_review_payload, repository
                            )
                            if message_request:
                                await self.msg_processor.process_message_request(message_request)
                                logger.info(f"AIå®¡æŸ¥æ¶ˆæ¯é€šçŸ¥å·²å‘é€: {repository}#{pr_number}")
                            else:
                                logger.warning(f"AIå®¡æŸ¥æ¶ˆæ¯è¯·æ±‚åˆ›å»ºå¤±è´¥: {repository}#{pr_number}")
                        except Exception as msg_error:
                            logger.error(f"å‘é€AIå®¡æŸ¥æ¶ˆæ¯é€šçŸ¥å¼‚å¸¸: {msg_error}")
                else:
                    logger.error(f"å®¡æŸ¥ç»“æœæäº¤å¤±è´¥: {repository}#{pr_number}")
                    # æäº¤å¤±è´¥æ—¶ä¹Ÿè¦ç§»é™¤å®¡æ ¸è¯·æ±‚
                    repo_config = self.config_manager.get_repository_config(repository)
                    bot_username = repo_config.get("allow_review", {}).get("bot_username", "")
                    await self._remove_review_and_comment(owner, repo, pr_number, bot_username, "å®¡æŸ¥ç»“æœæäº¤å¤±è´¥")
            else:
                logger.warning(f"å®¡æŸ¥æœªäº§ç”Ÿæœ‰æ•ˆç»“æœ: {repository}#{pr_number}")
                repo_config = self.config_manager.get_repository_config(repository)
                bot_username = repo_config.get("allow_review", {}).get("bot_username", "")
                if bot_username:
                    await self._remove_review_and_comment(
                        owner,
                        repo,
                        pr_number,
                        bot_username,
                        """å®¡æŸ¥æš‚æ—¶æ— æ³•å¤„ç†æ­¤PR

ğŸ’¡ **åŸå› **:
- å®¡æŸ¥æœªäº§ç”Ÿæœ‰æ•ˆç»“æœ

---
âœ¨ Powered by **baiyao105**' GitHub Bot""",
                    )
                    await api_client.remove_review_request(owner, repo, pr_number, [bot_username])

        except Exception as e:
            logger.error(f"ä»£ç å®¡æŸ¥å¼‚å¸¸: {repository}#{pr_number} - {e}")
            try:
                owner, repo = repository.split("/")
                repo_config = self.config_manager.get_repository_config(repository)
                bot_username = repo_config.get("allow_review", {}).get("bot_username", "")

                if bot_username:
                    await self._remove_review_and_comment(
                        owner,
                        repo,
                        pr_number,
                        bot_username,
                        f"""å®¡æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸

> [!CAUTION]
> ğŸ”§ **é”™è¯¯ä¿¡æ¯**: {str(e)}

---
âœ¨ Powered by **baiyao105**' GitHub Bot""",
                    )
                    api_client = self.github_processor._get_api_client(repository)
                    if api_client:
                        await api_client.remove_review_request(owner, repo, pr_number, [bot_username])
            except Exception as cleanup_error:
                logger.error(f"æ¸…ç†å®¡æŸ¥è¯·æ±‚æ—¶å¼‚å¸¸: {cleanup_error}")
        finally:
            # æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥éƒ½è¦ä»æ´»è·ƒå®¡æŸ¥é›†åˆä¸­ç§»é™¤
            self.active_reviews.discard(review_key)
            logger.debug(f"å·²ä»æ´»è·ƒå®¡æŸ¥é›†åˆä¸­ç§»é™¤: {review_key}")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        uptime = current_time - self.last_reset_time
        return {
            "uptime_seconds": uptime,
            "queue_size": self.event_queue.qsize(),
            "is_processing": self.is_processing,
            "event_stats": dict(self.event_stats),
            "total_events": sum(self.event_stats.values()),
            "delivery_cache_size": len(self.delivery_cache),
            "supported_events": list(self.supported_events),
        }

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.event_stats.clear()
        self.last_reset_time = time.time()
        logger.success("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")

    def clear_delivery_cache(self):
        """æ¸…ç†æŠ•é€’ç¼“å­˜"""
        self.delivery_cache.clear()
        logger.success("æŠ•é€’ç¼“å­˜å·²æ¸…ç†")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.stop_processing()
        self.delivery_cache.clear()
        self.event_stats.clear()
        while not self.event_queue.empty():
            try:
                self.event_queue.get_nowait()
                self.event_queue.task_done()
            except asyncio.QueueEmpty:
                break

        logger.success("å¤„ç†å™¨å·²æ¸…ç†")


# å…¨å±€Webhookå¤„ç†å™¨å®ä¾‹
_webhook_processor = None


def get_webhook_processor(config_manager) -> WebhookProcessor:
    """è·å–å…¨å±€Webhookå¤„ç†å™¨å®ä¾‹"""
    global _webhook_processor
    if _webhook_processor is None:
        _webhook_processor = WebhookProcessor(config_manager)
    return _webhook_processor


async def cleanup_webhook_processor():
    """æ¸…ç†Webhookå¤„ç†å™¨èµ„æº"""
    global _webhook_processor
    if _webhook_processor:
        await _webhook_processor.cleanup()
        _webhook_processor = None
